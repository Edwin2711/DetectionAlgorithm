{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2VLA8UzWPsKDVUDdICd/s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Edwin2711/DetectionAlgorithm/blob/main/PruebaAlt2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7Xt7PMIaxOT"
      },
      "outputs": [],
      "source": [
        "#Load libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import glob\n",
        "import torch.nn as nn\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "import pathlib\n",
        "\n",
        "import cv2\n",
        "import pathlib\n",
        "from PIL import Image\n",
        "from io import open\n",
        "import torch.functional as F\n",
        "from torchvision.models import squeezenet1_1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#checking for device\n",
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJUPH4x4a3ok",
        "outputId": "0ba7d6bb-fdbf-4e32-8609-68675a3d6a9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Transforms\n",
        "transformer=transforms.Compose([\n",
        "    transforms.Resize((150,150)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),  #0-255 to 0-1, numpy to tensors\n",
        "    transforms.Normalize([0.5,0.5,0.5], # 0-1 to [-1,1] , formula (x-mean)/std\n",
        "                        [0.5,0.5,0.5])\n",
        "])"
      ],
      "metadata": {
        "id": "-D6YV44abJZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/tanks.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "My9vpNgfbacH",
        "outputId": "43698f47-043c-443a-b826-51f9edc1d657"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/tanks.zip\n",
            "   creating: tanks/pred/\n",
            "  inflating: tanks/pred/c1.jpg       \n",
            "  inflating: tanks/pred/c5.jpg       \n",
            "  inflating: tanks/pred/c6.jpg       \n",
            "  inflating: tanks/pred/s2.jpg       \n",
            "  inflating: tanks/pred/s5.jpg       \n",
            "  inflating: tanks/pred/s6.jpg       \n",
            "   creating: tanks/test/\n",
            "   creating: tanks/test/composite/\n",
            "  inflating: tanks/test/composite/c1.jpg  \n",
            "  inflating: tanks/test/composite/c2.jpg  \n",
            "  inflating: tanks/test/composite/c3.jpg  \n",
            "  inflating: tanks/test/composite/c4.jpg  \n",
            "  inflating: tanks/test/composite/c5.jpg  \n",
            "  inflating: tanks/test/composite/c6.jpg  \n",
            "   creating: tanks/test/steel/\n",
            "  inflating: tanks/test/steel/s1.jpg  \n",
            "  inflating: tanks/test/steel/s2.jpg  \n",
            "  inflating: tanks/test/steel/s3.jpg  \n",
            "  inflating: tanks/test/steel/s4.jpg  \n",
            "  inflating: tanks/test/steel/s5.jpg  \n",
            "  inflating: tanks/test/steel/s6.jpg  \n",
            "   creating: tanks/train/\n",
            "   creating: tanks/train/composite/\n",
            "  inflating: tanks/train/composite/c1.jpg  \n",
            "  inflating: tanks/train/composite/c10.jpg  \n",
            "  inflating: tanks/train/composite/c2.jpg  \n",
            "  inflating: tanks/train/composite/c3.jpg  \n",
            "  inflating: tanks/train/composite/c4.jpg  \n",
            "  inflating: tanks/train/composite/c5.jpg  \n",
            "  inflating: tanks/train/composite/c6.jpg  \n",
            "  inflating: tanks/train/composite/c7.jpg  \n",
            "  inflating: tanks/train/composite/c8.jpg  \n",
            "  inflating: tanks/train/composite/c9.jpg  \n",
            "   creating: tanks/train/steel/\n",
            "  inflating: tanks/train/steel/prueba.jpg  \n",
            "  inflating: tanks/train/steel/prueba10.jpg  \n",
            "  inflating: tanks/train/steel/Prueba2.jpg  \n",
            "  inflating: tanks/train/steel/prueba3.jpg  \n",
            "  inflating: tanks/train/steel/prueba4.jpg  \n",
            "  inflating: tanks/train/steel/prueba5.jpg  \n",
            "  inflating: tanks/train/steel/prueba6.jpg  \n",
            "  inflating: tanks/train/steel/prueba7.jpg  \n",
            "  inflating: tanks/train/steel/prueba8.jpg  \n",
            "  inflating: tanks/train/steel/prueba9.jpg  \n",
            "   creating: tanks/valid/\n",
            "   creating: tanks/valid/composite/\n",
            "  inflating: tanks/valid/composite/c1.jpg  \n",
            "   creating: tanks/valid/steel/\n",
            "  inflating: tanks/valid/steel/s1.jpg  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataloader\n",
        "\n",
        "#Path for training and testing directory\n",
        "train_path='tanks/train'\n",
        "test_path='tanks/test'\n",
        "\n",
        "train_loader=DataLoader(\n",
        "    torchvision.datasets.ImageFolder(train_path,transform=transformer),\n",
        "    batch_size=64, shuffle=True\n",
        ")\n",
        "test_loader=DataLoader(\n",
        "    torchvision.datasets.ImageFolder(test_path,transform=transformer),\n",
        "    batch_size=32, shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "8wwN6kAtbN89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#categories\n",
        "root=pathlib.Path(train_path)\n",
        "classes=sorted([j.name.split('/')[-1] for j in root.iterdir()])\n",
        "print(classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cn22-mv5b8JU",
        "outputId": "a99b3861-c9ed-48d7-bc27-7a30274dfdcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['composite', 'steel']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN Network\n",
        "\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self,num_classes=2):\n",
        "        super(ConvNet,self).__init__()\n",
        "        \n",
        "        #Output size after convolution filter\n",
        "        #((w-f+2P)/s) +1\n",
        "        \n",
        "        #Input shape= (32,3,150,150)\n",
        "        \n",
        "        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n",
        "        #Shape= (32,12,150,150)\n",
        "        self.bn1=nn.BatchNorm2d(num_features=12)\n",
        "        #Shape= (32,12,150,150)\n",
        "        self.relu1=nn.ReLU()\n",
        "        #Shape= (32,12,150,150)\n",
        "        \n",
        "        self.pool=nn.MaxPool2d(kernel_size=2)\n",
        "        #Reduce the image size be factor 2\n",
        "        #Shape= (32,12,75,75)\n",
        "        \n",
        "        \n",
        "        self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n",
        "        #Shape= (32,20,75,75)\n",
        "        self.relu2=nn.ReLU()\n",
        "        #Shape= (32,20,75,75)\n",
        "        \n",
        "        \n",
        "        \n",
        "        self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
        "        #Shape= (32,32,75,75)\n",
        "        self.bn3=nn.BatchNorm2d(num_features=32)\n",
        "        #Shape= (32,32,75,75)\n",
        "        self.relu3=nn.ReLU()\n",
        "        #Shape= (32,32,75,75)\n",
        "        \n",
        "        \n",
        "        self.fc=nn.Linear(in_features=75 * 75 * 32,out_features=num_classes)\n",
        "\n",
        "        #Feed forwad function\n",
        "        \n",
        "    def forward(self,input):\n",
        "        output=self.conv1(input)\n",
        "        output=self.bn1(output)\n",
        "        output=self.relu1(output)\n",
        "            \n",
        "        output=self.pool(output)\n",
        "            \n",
        "        output=self.conv2(output)\n",
        "        output=self.relu2(output)\n",
        "            \n",
        "        output=self.conv3(output)\n",
        "        output=self.bn3(output)\n",
        "        output=self.relu3(output)\n",
        "            \n",
        "            \n",
        "            #Above output will be in matrix form, with shape (256,32,75,75)\n",
        "            \n",
        "        output=output.view(-1,32*75*75)\n",
        "            \n",
        "            \n",
        "        output=self.fc(output)\n",
        "            \n",
        "        return output"
      ],
      "metadata": {
        "id": "BkBGS-X1cINJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=ConvNet(num_classes=2).to(device)"
      ],
      "metadata": {
        "id": "hRF4IJ4YfnVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Optmizer and loss function\n",
        "optimizer=Adam(model.parameters(),lr=0.001,weight_decay=0.0001)\n",
        "loss_function=nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "MSuX18P3fyF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs=20\n",
        "#calculating the size of training and testing images\n",
        "train_count=len(glob.glob(train_path+'/**/*.jpg'))\n",
        "test_count=len(glob.glob(test_path+'/**/*.jpg'))\n",
        "print(train_count,test_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhSHWw6Ifz5s",
        "outputId": "72e90383-bc82-4060-ebbc-ea89c6f3fbe5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model training and saving best model\n",
        "\n",
        "best_accuracy=0.0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    #Evaluation and training on training dataset\n",
        "    model.train()\n",
        "    train_accuracy=0.0\n",
        "    train_loss=0.0\n",
        "    \n",
        "    for i, (images,labels) in enumerate(train_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            images=Variable(images.cuda())\n",
        "            labels=Variable(labels.cuda())\n",
        "            \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        outputs=model(images)\n",
        "        loss=loss_function(outputs,labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        \n",
        "        train_loss+= loss.cpu().data*images.size(0)\n",
        "        _,prediction=torch.max(outputs.data,1)\n",
        "        \n",
        "        train_accuracy+=int(torch.sum(prediction==labels.data))\n",
        "        \n",
        "    train_accuracy=train_accuracy/train_count\n",
        "    train_loss=train_loss/train_count\n",
        "\n",
        "    \n",
        "    # Evaluation on testing dataset\n",
        "    model.eval()\n",
        "    \n",
        "    test_accuracy=0.0\n",
        "    for i, (images,labels) in enumerate(test_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            images=Variable(images.cuda())\n",
        "            labels=Variable(labels.cuda())\n",
        "            \n",
        "        outputs=model(images)\n",
        "        _,prediction=torch.max(outputs.data,1)\n",
        "        test_accuracy+=int(torch.sum(prediction==labels.data))\n",
        "    \n",
        "    test_accuracy=test_accuracy/test_count\n",
        "    \n",
        "    \n",
        "    print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))\n",
        "    \n",
        "    #Save the best model\n",
        "    if test_accuracy>best_accuracy:\n",
        "        torch.save(model.state_dict(),'best_checkpoint.model')\n",
        "        best_accuracy=test_accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gvp35T7LgPf9",
        "outputId": "347180f5-402e-4735-f162-404f1b50ca5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 Train Loss: tensor(0.7193) Train Accuracy: 0.45 Test Accuracy: 0.5\n",
            "Epoch: 1 Train Loss: tensor(11.5041) Train Accuracy: 0.75 Test Accuracy: 0.5833333333333334\n",
            "Epoch: 2 Train Loss: tensor(0.6264) Train Accuracy: 0.95 Test Accuracy: 0.4166666666666667\n",
            "Epoch: 3 Train Loss: tensor(2.1582) Train Accuracy: 0.85 Test Accuracy: 0.4166666666666667\n",
            "Epoch: 4 Train Loss: tensor(0.4938) Train Accuracy: 0.95 Test Accuracy: 0.4166666666666667\n",
            "Epoch: 5 Train Loss: tensor(1.7881e-08) Train Accuracy: 1.0 Test Accuracy: 0.4166666666666667\n",
            "Epoch: 6 Train Loss: tensor(0.) Train Accuracy: 1.0 Test Accuracy: 0.4166666666666667\n",
            "Epoch: 7 Train Loss: tensor(0.) Train Accuracy: 1.0 Test Accuracy: 0.4166666666666667\n",
            "Epoch: 8 Train Loss: tensor(0.) Train Accuracy: 1.0 Test Accuracy: 0.4166666666666667\n",
            "Epoch: 9 Train Loss: tensor(0.) Train Accuracy: 1.0 Test Accuracy: 0.4166666666666667\n",
            "Epoch: 10 Train Loss: tensor(0.) Train Accuracy: 1.0 Test Accuracy: 0.5\n",
            "Epoch: 11 Train Loss: tensor(0.) Train Accuracy: 1.0 Test Accuracy: 0.6666666666666666\n",
            "Epoch: 12 Train Loss: tensor(0.) Train Accuracy: 1.0 Test Accuracy: 0.75\n",
            "Epoch: 13 Train Loss: tensor(0.) Train Accuracy: 1.0 Test Accuracy: 0.75\n",
            "Epoch: 14 Train Loss: tensor(0.) Train Accuracy: 1.0 Test Accuracy: 0.75\n",
            "Epoch: 15 Train Loss: tensor(0.) Train Accuracy: 1.0 Test Accuracy: 0.75\n",
            "Epoch: 16 Train Loss: tensor(0.) Train Accuracy: 1.0 Test Accuracy: 0.75\n",
            "Epoch: 17 Train Loss: tensor(0.) Train Accuracy: 1.0 Test Accuracy: 0.75\n",
            "Epoch: 18 Train Loss: tensor(0.) Train Accuracy: 1.0 Test Accuracy: 0.75\n",
            "Epoch: 19 Train Loss: tensor(0.) Train Accuracy: 1.0 Test Accuracy: 0.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_path='tanks/pred'\n",
        "checkpoint=torch.load('best_checkpoint.model')\n",
        "model=ConvNet(num_classes=2)\n",
        "model.load_state_dict(checkpoint)\n",
        "model.eval()\n",
        "\n",
        "#Transforms\n",
        "transformer=transforms.Compose([\n",
        "    transforms.Resize((150,150)),\n",
        "    transforms.ToTensor(),  #0-255 to 0-1, numpy to tensors\n",
        "    transforms.Normalize([0.5,0.5,0.5], # 0-1 to [-1,1] , formula (x-mean)/std\n",
        "                        [0.5,0.5,0.5])\n",
        "])"
      ],
      "metadata": {
        "id": "yKyEx9VHrNuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction function\n",
        "def prediction(img_path,transformer):\n",
        "    \n",
        "    image=Image.open(img_path)\n",
        "    \n",
        "    image_tensor=transformer(image).float()\n",
        "    \n",
        "    \n",
        "    image_tensor=image_tensor.unsqueeze_(0)\n",
        "    \n",
        "    if torch.cuda.is_available():\n",
        "        image_tensor.cuda()\n",
        "        \n",
        "    input=Variable(image_tensor)\n",
        "    \n",
        "    \n",
        "    output=model(input)\n",
        "    \n",
        "    index=output.data.numpy().argmax()\n",
        "    \n",
        "    pred=classes[index]\n",
        "    \n",
        "    return pred\n",
        "    "
      ],
      "metadata": {
        "id": "sjYXb8nZrwkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_path=glob.glob(pred_path+'/*.jpg')\n",
        "pred_dict={}\n",
        "\n",
        "for i in images_path:\n",
        "    print(i)\n",
        "    pred_dict[i[i.rfind('/')+1:]]=prediction(i,transformer)\n",
        "pred_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bgVxQt8r33s",
        "outputId": "bd0b4527-2779-4880-923a-ac2fadab33d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tanks/pred/c5.jpg\n",
            "tanks/pred/s6.jpg\n",
            "tanks/pred/s2.jpg\n",
            "tanks/pred/c6.jpg\n",
            "tanks/pred/s5.jpg\n",
            "tanks/pred/c1.jpg\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'c5.jpg': 'composite',\n",
              " 's6.jpg': 'steel',\n",
              " 's2.jpg': 'steel',\n",
              " 'c6.jpg': 'composite',\n",
              " 's5.jpg': 'composite',\n",
              " 'c1.jpg': 'composite'}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}